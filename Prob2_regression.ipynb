{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Instructions to students:\n",
    "\n",
    "1. There are 5 types of cells in this notebook. The cell type will be indicated within the cell.\n",
    "    1. Markdown cells with problem written in it. (DO NOT TOUCH THESE CELLS) (**Cell type: TextRead**)\n",
    "    2. Python cells with setup code for further evaluations. (DO NOT TOUCH THESE CELLS) (**Cell type: CodeRead**)\n",
    "    3. Python code cells with some template code or empty cell. (FILL CODE IN THESE CELLS BASED ON INSTRUCTIONS IN CURRENT AND PREVIOUS CELLS) (**Cell type: CodeWrite**)\n",
    "    4. Markdown cells where a written reasoning or conclusion is expected. (WRITE SENTENCES IN THESE CELLS) (**Cell type: TextWrite**)\n",
    "    5. Temporary code cells for convenience and TAs. (YOU MAY DO WHAT YOU WILL WITH THESE CELLS, TAs WILL REPLACE WHATEVER YOU WRITE HERE WITH OFFICIAL EVALUATION CODE) (**Cell type: Convenience**)\n",
    "    \n",
    "2. You are not allowed to insert new cells in the submitted notebook.\n",
    "\n",
    "3. You are not allowed to import any extra packages.\n",
    "\n",
    "4. The code is to be written in Python 3.6 syntax. Latest versions of other packages maybe assumed.\n",
    "\n",
    "5. In CodeWrite Cells, the only outputs to be given are plots asked in the question. Nothing else to be output/print. \n",
    "\n",
    "6. If TextWrite cells ask you to give accuracy/error/other numbers you can print them on the code cells, but remove the print statements before submitting.\n",
    "\n",
    "7. The convenience code can be used to check the expected syntax of the functions. At a minimum, your entire notebook must run with \"run all\" with the convenience cells as it is. Any runtime failures on the submitted notebook as it is will get zero marks.\n",
    "\n",
    "8. All code must be written by yourself. Copying from other students/material on the web is strictly prohibited. Any violations will result in zero marks.\n",
    "\n",
    "9. All datasets will be given as .npz files, and will contain data in 4 numpy arrays :\"X_train, Y_train, X_test, Y_test\". In that order. The meaning of the 4 arrays can be easily inferred from their names.\n",
    "\n",
    "10. All plots must be labelled properly, all tables must have rows and columns named properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CodeRead\n",
    "\n",
    "data_folder = '../Data_contest/dataset/'\n",
    "\n",
    "\n",
    "genome_scores_df=pd.read_csv(data_folder+'genome_scores.csv') # Large (500MB)\n",
    "movies_df=pd.read_csv(data_folder+'movies.csv')\n",
    "train_df=pd.read_csv(data_folder+'train.csv') # Large 500MB\n",
    "validation_df = pd.read_csv(data_folder+'validation.csv') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CodeRead\n",
    "\n",
    "# create movie rating dataset from train\n",
    "\n",
    "# Feature vector for the 10000 movies, each with a 1128 dimensional vector. \n",
    "# If a movie doesn't appear in genome_scores we make it simply the 0 vector.\n",
    "X=np.zeros((10000,1128)) \n",
    "movies_with_featvecs=set(genome_scores_df['movieId'])\n",
    "# The average rating, for each of the movies in the training set. \n",
    "# -1 if it is not in the train set.\n",
    "rating_movies = -1*np.ones(10000) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Each movie, is labelled +1 or -1 based on whetherr it is a comedy or not\n",
    "\n",
    "for i in range(10000):\n",
    "    if i not in movies_with_featvecs:\n",
    "        continue\n",
    "    temp = genome_scores_df[genome_scores_df['movieId']==i]\n",
    "    feat_vec= np.array(temp['relevance'])\n",
    "    X[i,:]=feat_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10000):\n",
    "    temp = train_df[train_df['movieId']==i]\n",
    "    if len(temp)==0:\n",
    "        continue\n",
    "    ratings_curr_movies = temp['rating']\n",
    "    rating_movies[i] = np.mean(ratings_curr_movies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = []\n",
    "for i in range(10000):\n",
    "    temp = movies_df[movies_df['movieId']==i]\n",
    "    if len(temp)==0:\n",
    "        continue\n",
    "    temp = temp['genres'].values[0]\n",
    "    temp = temp.split('|')\n",
    "    for genre in temp:\n",
    "        if genre not in all_genres:\n",
    "            all_genres.append(genre)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_genre = np.zeros((10000,19))\n",
    "\n",
    "for i in range(10000):\n",
    "    temp = movies_df[movies_df['movieId']==i]\n",
    "    if len(temp)==0:\n",
    "        continue\n",
    "    temp = temp['genres'].values[0]\n",
    "    temp = temp.split('|')\n",
    "    \n",
    "    for idx, genre in enumerate(all_genres):\n",
    "        X_genre[i,idx] = genre in temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1147)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_concat = np.concatenate((X,X_genre),axis=1)\n",
    "X_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3601078084681526"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_df['rating']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextWrite cell. Report test accuracies for different k here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: PCA and regression\n",
    "\n",
    "Take the regression dataset below, and perform linear regression after doing PCA on the feature vector. \n",
    "\n",
    "For each K in [4,32,256,1024] take the top k components and report the mean squared error on the test set below. \n",
    "\n",
    "For each K you can choose the regularisation hyperparameter $\\lambda$ for linear regression using a 80-20 split of the training set. \n",
    "\n",
    "For each K above, report the best lambda and the mean squared error for this best lambda in the cell below the next.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeWrite\n",
    "\n",
    "X_all = X_concat[rating_movies>0]\n",
    "Y_all = rating_movies[rating_movies>0]\n",
    "\n",
    "X_train = np.array(X_all[:7000])\n",
    "Y_train = np.array(Y_all[:7000])\n",
    "X_test = np.array(X_all[7000:])\n",
    "Y_test = np.array(Y_all[7000:])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SVM_func(X_train, Y_train, kernel, C=1, kernel_param=1):\n",
    "    if kernel == 'linear':\n",
    "        SVM_algo =  SVR(C=C, kernel=kernel)\n",
    "    if kernel == 'poly':\n",
    "        SVM_algo =  SVR(C=C, kernel=kernel, degree = kernel_param)\n",
    "    else:\n",
    "        SVM_algo =  SVR(C=C, kernel=kernel, gamma = kernel_param)\n",
    "\n",
    "    classifier = SVM_algo.fit(X_train,Y_train)\n",
    "#     Y_test_pred = classifier.decision_function(X_test)\n",
    "    return classifier\n",
    "\n",
    "def best_hyperparam(X_train, Y_train, kernel):\n",
    "    split = int(0.7*X_train.shape[0])\n",
    "    X_train1 = X_train[:split]\n",
    "    X_val = X_train[split:]\n",
    "    Y_train1 = Y_train[:split]\n",
    "    Y_val = Y_train[split:]\n",
    "    best_loss = 10000\n",
    "    best_kernel_param = 1\n",
    "    best_reg_param = 0\n",
    "    \n",
    "    #reg_params = [0.0001]\n",
    "\n",
    "#     if kernel == 'linear':\n",
    "#         kernel_param = 1\n",
    "#         for C in reg_params:\n",
    "#             classifier = SVM_func(X_train1, Y_train1, kernel, C, kernel_param)\n",
    "#             Y_val_pred1 = classifier.decision_function(X_val)\n",
    "#             Y_val_pred = np.where(Y_val_pred1>0,1,-1)\n",
    "#             zero_one_loss = np.where(Y_val_pred != Y_val,1,0)\n",
    "#             mean_zero_one_loss = np.mean(zero_one_loss)\n",
    "#             if mean_zero_one_loss < best_zero_one_loss:\n",
    "#                 best_zero_one_loss = mean_zero_one_loss\n",
    "#                 best_kernel_param = kernel_param\n",
    "#                 best_reg_param = C\n",
    "#             print('C ',C,'loss = ',mean_zero_one_loss)\n",
    "            \n",
    "#     #degree_params = [3]            \n",
    "#     degree_params = [1,3,5,9,15]                  \n",
    "#     if kernel =='poly':  \n",
    "#         for kernel_param in degree_params:\n",
    "#             for C in reg_params:\n",
    "#                 classifier = SVM_func(X_train1, Y_train1, kernel, C, kernel_param)\n",
    "#                 Y_val_pred1 = classifier.decision_function(X_val)\n",
    "#                 Y_val_pred = np.where(Y_val_pred1>0,1,-1)\n",
    "#                 zero_one_loss = np.where(Y_val_pred != Y_val,1,0)\n",
    "#                 mean_zero_one_loss = np.mean(zero_one_loss)\n",
    "#                 if mean_zero_one_loss < best_zero_one_loss:\n",
    "#                     best_zero_one_loss = mean_zero_one_loss\n",
    "#                     best_kernel_param = kernel_param\n",
    "#                     best_reg_param = C\n",
    "#                 #print('C ',C,'degree ', kernel_param, 'loss = ',mean_zero_one_loss)\n",
    "\n",
    "\n",
    "    reg_params = [1e3,1e2,1e1,1,1e-1,1e-2]\n",
    "    rbf_lambda_params = [1e-5,1e-3,1e-1,1,10,1e2] # rbf only\n",
    "    if kernel =='rbf':\n",
    "        for kernel_param in rbf_lambda_params:\n",
    "            for C in reg_params:\n",
    "                classifier = SVM_func(X_train1, Y_train1, kernel, C, kernel_param)\n",
    "                Y_val_pred = classifier.predict(X_val)\n",
    "                mse_loss = np.mean((Y_val_pred - Y_val)**2)\n",
    "                if mse_loss < best_loss:\n",
    "                    best_loss = mse_loss\n",
    "                    best_kernel_param = kernel_param\n",
    "                    best_reg_param = C\n",
    "                print('C ',C,'lambda ', kernel_param, 'loss = ',mse_loss)\n",
    "\n",
    "\n",
    "                    \n",
    "    return best_kernel_param, best_reg_param\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C  1000.0 lambda  1e-05 loss =  0.02559231890136304\n",
      "C  100.0 lambda  1e-05 loss =  0.03180249615654678\n"
     ]
    }
   ],
   "source": [
    "kernel = 'rbf'\n",
    "# best_kernel_param = 0.1 \n",
    "# best_reg_param = 10\n",
    "\n",
    "best_kernel_param, best_reg_param = best_hyperparam(X_all, Y_all, kernel)\n",
    "# 0.001, 10 according to best_hyperparam()\n",
    "# 0.1,   10 according to submission\n",
    "\n",
    "classifier = SVM_func(X_all, Y_all, kernel, C = best_reg_param, kernel_param = best_kernel_param)\n",
    "\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "train_zero_one_loss = np.mean((Y_train_pred - Y_train)**2)\n",
    "test_zero_one_loss = np.mean((Y_test_pred - Y_test)**2)\n",
    "print(\"zero_one loss train  , test = \",train_zero_one_loss,\" , \",test_zero_one_loss)\n",
    "print('best params', best_kernel_param, best_reg_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_one loss train  , test =  0.009417467803048247  ,  0.010346241350575927\n",
    "# best_kernel_param = 0.001 \n",
    "# best_reg_param = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_concat\n",
    "X_all.shape\n",
    "Y_pred_all = classifier.predict(X_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission\n",
    "\n",
    "df_test=pd.read_csv(data_folder+'test.csv') # Large 500MB\n",
    "\n",
    "predictions = np.zeros(len(df_test))\n",
    "for i in range(len(df_test)):\n",
    "    userid =  df_test.iloc[i,0]\n",
    "    movieid = df_test.iloc[i,1]\n",
    "    rating = float(\"{0:.1f}\".format(Y_pred_all[movieid]))\n",
    "    if rating>5:\n",
    "        rating = 5\n",
    "    if rating<0.5:\n",
    "        rating =0.5\n",
    "    predictions[i] = rating\n",
    "df_submission = pd.read_csv(data_folder+'dummy_submission.csv')\n",
    "df_submission.Prediction = predictions\n",
    "df_submission.to_csv('./Submission_regression_concat2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
