{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 0\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge as KRR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "print(\"Preparing training files....\")\n",
    "data_folder = '../Data_contest/dataset/'\n",
    "\n",
    "genome_scores_df=pd.read_csv(data_folder+'genome_scores.csv') # Large (500MB)\n",
    "movies_df=pd.read_csv(data_folder+'movies.csv')\n",
    "df_test=pd.read_csv(data_folder+'test.csv') # Large 500MB\n",
    "df_submission = pd.read_csv(data_folder+'dummy_submission.csv')\n",
    "\n",
    "df_train_partial = pd.read_csv(data_folder+'train.csv')\n",
    "df_valid_partial = pd.read_csv(data_folder+'validation.csv')\n",
    "\n",
    "#Concatenating train and validation set\n",
    "df_valid_partial=df_valid_partial.drop('timestamp',axis=1)\n",
    "df_new_train = pd.concat([df_train_partial, df_valid_partial])\n",
    "df_train_full=df_new_train.reset_index(drop=True)\n",
    "train_df = df_train_full\n",
    "\n",
    "train = train_df\n",
    "test = df_test\n",
    "test_df= df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NORMAL REGRESSION ###\n",
    "\n",
    "# create movie rating dataset from train\n",
    "\n",
    "# Feature vector for the 10000 movies, each with a 1128 dimensional vector. \n",
    "# If a movie doesn't appear in genome_scores we make it simply the 0 vector.\n",
    "\n",
    "def generate_XY():\n",
    "    X=np.zeros((10000,1128)) \n",
    "\n",
    "    movies_with_featvecs=set(genome_scores_df['movieId'])\n",
    "    # The average rating, for each of the movies in the training set. \n",
    "    # -1 if it is not in the train set.\n",
    "    rating_movies = -1*np.ones(10000) \n",
    "\n",
    "\n",
    "    # Each movie, is labelled +1 or -1 based on whetherr it is a comedy or not\n",
    "\n",
    "    for i in range(10000):\n",
    "        if i not in movies_with_featvecs:\n",
    "            continue\n",
    "        temp = genome_scores_df[genome_scores_df['movieId']==i]\n",
    "        feat_vec= np.array(temp['relevance'])\n",
    "        X[i,:]=feat_vec\n",
    "\n",
    "\n",
    "    for i in range(10000):\n",
    "        temp = train_df[train_df['movieId']==i]\n",
    "        if len(temp)==0:\n",
    "            continue\n",
    "        ratings_curr_movies = temp['rating']\n",
    "        rating_movies[i] = np.mean(ratings_curr_movies)\n",
    "\n",
    "\n",
    "    all_genres = []\n",
    "    for i in range(10000):\n",
    "        temp = movies_df[movies_df['movieId']==i]\n",
    "        if len(temp)==0:\n",
    "            continue\n",
    "        temp = temp['genres'].values[0]\n",
    "        temp = temp.split('|')\n",
    "        for genre in temp:\n",
    "            if genre not in all_genres:\n",
    "                all_genres.append(genre)\n",
    "\n",
    "    X_genre = np.zeros((10000,19))\n",
    "\n",
    "    for i in range(10000):\n",
    "        temp = movies_df[movies_df['movieId']==i]\n",
    "        if len(temp)==0:\n",
    "            continue\n",
    "        temp = temp['genres'].values[0]\n",
    "        temp = temp.split('|')\n",
    "\n",
    "        for idx, genre in enumerate(all_genres):\n",
    "            X_genre[i,idx] = genre in temp\n",
    "\n",
    "    X_concat = np.concatenate((X,X_genre),axis=1)\n",
    "    return X_concat, rating_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVR_Predictions(X, rating_movies):\n",
    "    X_all = X[rating_movies>0]\n",
    "    Y_all = rating_movies[rating_movies>0]\n",
    "\n",
    "    best_kernel_param = 0.1\n",
    "    best_reg_param = 10\n",
    "\n",
    "    SVM_algo   = SVR(C=best_reg_param, kernel='rbf', gamma = best_kernel_param)\n",
    "    classifier = SVM_algo.fit(X_all,Y_all)\n",
    "\n",
    "    X_all_full = X\n",
    "    Y_pred_all = classifier.predict(X_all_full)\n",
    "    return Y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done generation of X\n",
      "done SVR Predictions\n"
     ]
    }
   ],
   "source": [
    "X, rating_movies = generate_XY()\n",
    "print('done generation of X')\n",
    "Y_pred_all = SVR_Predictions(X, rating_movies)\n",
    "print('done SVR Predictions')\n",
    "# time = 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER BASED REGRESSION ###\n",
    "def userbased_regression():\n",
    "    kernel_param = 0.1\n",
    "    C = 10\n",
    "    alpha = 1/(2*C)\n",
    "\n",
    "    #For user specific\n",
    "    rating_pred = np.zeros((10000,10000))\n",
    "\n",
    "    for userId in range(10000):\n",
    "        User_specific = train_df.loc[train_df['userId'] == userId]\n",
    "        User_specific_test = test_df.loc[test_df['userId'] == userId]\n",
    "        if (len(User_specific)!=0) and (len(User_specific_test)!=0):\n",
    "            X_training_matrix = X[User_specific.movieId,:]\n",
    "            Y_training_matrix = User_specific.rating\n",
    "            X_testing_matrix = X[User_specific_test.movieId,:]\n",
    "            list_movieId = User_specific_test.movieId\n",
    "            SVM_algo =  KRR(kernel='rbf')\n",
    "            classifier = SVM_algo.fit(X_training_matrix,Y_training_matrix)\n",
    "            Y_test_pred_matrix = classifier.predict(X_testing_matrix)\n",
    "            rating_pred[userId,list_movieId.values] = Y_test_pred_matrix\n",
    "    return rating_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_pred = userbased_regression()\n",
    "# time = 13 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rectifying zero values of user regression values\n",
    "user_regression = np.zeros(len(df_test))\n",
    "for i in range(len(df_test)):\n",
    "    userid =  df_test.iloc[i,0]\n",
    "    movieid = df_test.iloc[i,1]\n",
    "    #movie_based\n",
    "    rating_movie = Y_pred_all[movieid]\n",
    "    #user based\n",
    "    rating_user = rating_pred[userid,movieid]\n",
    "    if rating_user==0:\n",
    "        rating_user = rating_movie\n",
    "    user_regression[i] = rating_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del genome_scores_df\n",
    "del movies_df\n",
    "del df_train_partial\n",
    "del df_valid_partial\n",
    "del df_new_train\n",
    "del df_train_full\n",
    "del train_df\n",
    "del rating_pred\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahulchakwate/.local/lib/python3.5/site-packages/ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting truncated svd with number of components as 20\n",
      "Iteration: 0 , Loss: 0.03479949429989589 \n",
      "Iteration: 1 , Loss: 0.032224295535297466 \n",
      "Iteration: 2 , Loss: 0.0309201725252048 \n",
      "Iteration: 3 , Loss: 0.030106318779451614 \n",
      "Iteration: 4 , Loss: 0.029540719096839023 \n",
      "Iteration: 5 , Loss: 0.02912054884848634 \n",
      "Iteration: 6 , Loss: 0.028793844301178782 \n",
      "Iteration: 7 , Loss: 0.02853121565475046 \n",
      "Iteration: 8 , Loss: 0.028314662193518247 \n",
      "Iteration: 9 , Loss: 0.02813248196795701 \n",
      "Done\n",
      "Starting truncated svd with number of components as 15\n",
      "Iteration: 0 , Loss: 0.029248006977834255 \n",
      "Iteration: 1 , Loss: 0.029049771321375855 \n",
      "Iteration: 2 , Loss: 0.02890122865670532 \n",
      "Iteration: 3 , Loss: 0.02877887155015724 \n",
      "Iteration: 4 , Loss: 0.028674080401883066 \n",
      "Iteration: 5 , Loss: 0.028582389733088194 \n",
      "Iteration: 6 , Loss: 0.02850102318595533 \n",
      "Iteration: 7 , Loss: 0.0284280668959127 \n",
      "Iteration: 8 , Loss: 0.02836211618734 \n",
      "Iteration: 9 , Loss: 0.02830209693352745 \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### TRUNCSVD ###\n",
    "# ADD HERE\n",
    "\n",
    "#Due to adding of validation, we have some duplicates\n",
    "movie_matrix = pd.concat([train,test]).drop_duplicates(subset = ['userId','movieId'],keep = 'first')\n",
    "#Creates a movie matrix of #numofusers vs #noofmovies\n",
    "movie_matrix = movie_matrix.pivot('userId','movieId','rating')\n",
    "\n",
    "movie_means = movie_matrix.mean()\n",
    "user_means = movie_matrix.mean(axis=1)\n",
    "#Mean shifting\n",
    "movie_shifted_temp = movie_matrix-movie_means\n",
    "movie_shifted = movie_shifted_temp.fillna(0)\n",
    "#To get locations where we have ratings\n",
    "mask = -movie_shifted_temp.isnull()\n",
    "\n",
    "def repeated_matrix_reconstruction(num_pcs,num_iterations):\n",
    "    global movie_shifted\n",
    "    for i in range(num_iterations):\n",
    "        SVD = TruncatedSVD(n_components=num_pcs,random_state=42)\n",
    "        SVD.fit(movie_shifted)\n",
    "        #For the ease of applying masks we work with pandas\n",
    "        movie_represented =  pd.DataFrame(SVD.inverse_transform(SVD.transform(movie_shifted)),columns=movie_shifted.columns,index=movie_shifted.index)\n",
    "        loss = mean_squared_error(movie_represented[mask].fillna(0),movie_shifted_temp[mask].fillna(0))\n",
    "        print('Iteration: {} , Loss: {} '.format(i,loss))\n",
    "        #To just update the non-zero values of movie_reprented values to the true ratings\n",
    "        movie_represented[mask] = movie_shifted_temp[mask]\n",
    "        movie_shifted = movie_represented\n",
    "    #Mean shifting it back\n",
    "    movie_mat = movie_shifted + movie_means\n",
    "    movie_mat = movie_mat.clip(lower=0.5,upper=5)\n",
    "    return movie_mat\n",
    "print(\"Starting truncated svd with number of components as 20\")\n",
    "representative_matrix_20 = repeated_matrix_reconstruction(20,10)\n",
    "print(\"Done\")\n",
    "print(\"Starting truncated svd with number of components as 15\")\n",
    "representative_matrix_15 = repeated_matrix_reconstruction(15,10)\n",
    "print(\"Done\")\n",
    "#bagging\n",
    "rating_matrix = (representative_matrix_15+representative_matrix_20)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_prediction = np.zeros(len(test))\n",
    "for i in range(len(test)):\n",
    "    userid =  test.iloc[i,0]\n",
    "    movieid = test.iloc[i,1]\n",
    "    trunc_prediction[i] = rating_matrix[rating_matrix.index==userid][movieid].values[0]\n",
    "    \n",
    "indices=np.argwhere(np.isnan(trunc_prediction))\n",
    "trunc_prediction[indices] = user_regression[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLING\n",
    "\n",
    "PRED = (2*trunc_prediction + 1*user_regression)/3  # best 2:1\n",
    "PRED = np.around(PRED,1)\n",
    "\n",
    "PRED = np.clip(PRED, a_min = 0.5, a_max = 5)\n",
    "# SUBMISSION\n",
    "\n",
    "df_submission.Prediction = PRED\n",
    "df_submission.to_csv('./Goodfellas_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304958</th>\n",
       "      <td>2304958</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304959</th>\n",
       "      <td>2304959</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304960</th>\n",
       "      <td>2304960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304961</th>\n",
       "      <td>2304961</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304962</th>\n",
       "      <td>2304962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304963</th>\n",
       "      <td>2304963</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304964</th>\n",
       "      <td>2304964</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304965</th>\n",
       "      <td>2304965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304966</th>\n",
       "      <td>2304966</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304967</th>\n",
       "      <td>2304967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304968</th>\n",
       "      <td>2304968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304969</th>\n",
       "      <td>2304969</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304970</th>\n",
       "      <td>2304970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304971</th>\n",
       "      <td>2304971</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304972</th>\n",
       "      <td>2304972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304973</th>\n",
       "      <td>2304973</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304974</th>\n",
       "      <td>2304974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304975</th>\n",
       "      <td>2304975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304976</th>\n",
       "      <td>2304976</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304977</th>\n",
       "      <td>2304977</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304978</th>\n",
       "      <td>2304978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304979</th>\n",
       "      <td>2304979</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304980</th>\n",
       "      <td>2304980</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304981</th>\n",
       "      <td>2304981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304982</th>\n",
       "      <td>2304982</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304983</th>\n",
       "      <td>2304983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304984</th>\n",
       "      <td>2304984</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304985</th>\n",
       "      <td>2304985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304986</th>\n",
       "      <td>2304986</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304987</th>\n",
       "      <td>2304987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2304988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  Prediction\n",
       "0              0         3.9\n",
       "1              1         3.3\n",
       "2              2         2.4\n",
       "3              3         3.9\n",
       "4              4         3.4\n",
       "5              5         2.0\n",
       "6              6         3.9\n",
       "7              7         3.1\n",
       "8              8         3.7\n",
       "9              9         2.6\n",
       "10            10         2.7\n",
       "11            11         2.2\n",
       "12            12         3.3\n",
       "13            13         3.0\n",
       "14            14         2.5\n",
       "15            15         2.2\n",
       "16            16         2.7\n",
       "17            17         2.6\n",
       "18            18         3.0\n",
       "19            19         3.4\n",
       "20            20         2.4\n",
       "21            21         4.2\n",
       "22            22         1.7\n",
       "23            23         4.2\n",
       "24            24         3.2\n",
       "25            25         4.4\n",
       "26            26         2.9\n",
       "27            27         3.8\n",
       "28            28         3.6\n",
       "29            29         3.0\n",
       "...          ...         ...\n",
       "2304958  2304958         NaN\n",
       "2304959  2304959         NaN\n",
       "2304960  2304960         NaN\n",
       "2304961  2304961         NaN\n",
       "2304962  2304962         NaN\n",
       "2304963  2304963         NaN\n",
       "2304964  2304964         NaN\n",
       "2304965  2304965         NaN\n",
       "2304966  2304966         NaN\n",
       "2304967  2304967         NaN\n",
       "2304968  2304968         NaN\n",
       "2304969  2304969         NaN\n",
       "2304970  2304970         NaN\n",
       "2304971  2304971         NaN\n",
       "2304972  2304972         NaN\n",
       "2304973  2304973         NaN\n",
       "2304974  2304974         NaN\n",
       "2304975  2304975         NaN\n",
       "2304976  2304976         NaN\n",
       "2304977  2304977         NaN\n",
       "2304978  2304978         NaN\n",
       "2304979  2304979         NaN\n",
       "2304980  2304980         NaN\n",
       "2304981  2304981         NaN\n",
       "2304982  2304982         NaN\n",
       "2304983  2304983         NaN\n",
       "2304984  2304984         NaN\n",
       "2304985  2304985         NaN\n",
       "2304986  2304986         NaN\n",
       "2304987  2304987         NaN\n",
       "\n",
       "[2304988 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_regression[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304988"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.argwhere(np.isnan(trunc_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([318])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
